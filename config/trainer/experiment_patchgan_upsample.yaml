# Experiment: CycleGAN with upsample+conv decoder and PatchGAN discriminator

_base_: "base.yaml"

run_name: "monet-patchgan-upsample"
description: "CycleGAN with upsample+conv decoder and PatchGAN discriminator (no perceptual loss)"

s3:
  prefix: "monet-gan/models/patchgan-upsample"

wandb:
  tags:
    - "cyclegan"
    - "unet"
    - "patchgan"
    - "upsample"

generator:
  decoder:
    # Level 3: 4x4 -> 8x8, concat with encoder[10] (512ch) -> 1024ch input
    - type: upsample_conv
      in_channels: 1024
      out_channels: 512
      kernel_size: 3
      scale_factor: 2
      mode: bilinear
      norm: batch
      activation: relu
    - type: double_conv
      in_channels: 1024
      out_channels: 512
      kernel_size: 3
      norm: batch
      activation: relu
      dropout: 0.0
    - type: residual
      channels: 512
      kernel_size: 3
      norm: batch
      activation: relu
      dropout: 0.0
    
    # Level 2: 8x8 -> 16x16, concat with encoder[7] (256ch) -> 512ch input
    - type: upsample_conv
      in_channels: 512
      out_channels: 256
      kernel_size: 3
      scale_factor: 2
      mode: bilinear
      norm: batch
      activation: relu
    - type: double_conv
      in_channels: 512
      out_channels: 256
      kernel_size: 3
      norm: batch
      activation: relu
      dropout: 0.0
    - type: residual
      channels: 256
      kernel_size: 3
      norm: batch
      activation: relu
      dropout: 0.0
    
    # Level 1: 16x16 -> 32x32, concat with encoder[4] (128ch) -> 256ch input
    - type: upsample_conv
      in_channels: 256
      out_channels: 128
      kernel_size: 3
      scale_factor: 2
      mode: bilinear
      norm: batch
      activation: relu
    - type: double_conv
      in_channels: 256
      out_channels: 128
      kernel_size: 3
      norm: batch
      activation: relu
      dropout: 0.0
    - type: residual
      channels: 128
      kernel_size: 3
      norm: batch
      activation: relu
      dropout: 0.0
    
    # Level 0: 32x32 -> 64x64, concat with encoder[1] (64ch) -> 128ch input
    - type: upsample_conv
      in_channels: 128
      out_channels: 64
      kernel_size: 3
      scale_factor: 2
      mode: bilinear
      norm: batch
      activation: relu
    - type: double_conv
      in_channels: 128
      out_channels: 64
      kernel_size: 3
      norm: batch
      activation: relu
      dropout: 0.0
    - type: residual
      channels: 64
      kernel_size: 3
      norm: batch
      activation: relu
      dropout: 0.0

losses:
  gan_mode: lsgan
  cycle_loss_type: l1
  identity_loss_type: l1
  
  weights:
    adversarial: 1.0
    cycle: 10.0
    identity: 5.0
    perceptual: 0.0
    gradient_penalty: 0.0
